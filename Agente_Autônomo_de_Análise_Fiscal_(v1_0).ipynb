{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimbanica/Agente-Aut-nomo-de-An-lise-Fiscal-v1.0-/blob/main/Agente_Aut%C3%B4nomo_de_An%C3%A1lise_Fiscal_(v1_0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8jBcr0Y2k9N"
      },
      "outputs": [],
      "source": [
        "# C√âLULA 1: Instala√ß√µes\n",
        "print(\"Instalando depend√™ncias (OpenAI, Google/Gemini, Gradio, Langchain)...\")\n",
        "!pip install gradio pandas langchain langchain-experimental langchain-community llama-cpp-python openai tabulate python-multipart langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fITzUd3s5Dq1"
      },
      "outputs": [],
      "source": [
        "# C√âLULA 2: Leitura Segura das Chaves de API\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Tenta ler as chaves do Cofre de Senhas\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    if not os.environ[\"OPENAI_API_KEY\"]:\n",
        "        print(\"ATEN√á√ÉO: Chave 'OPENAI_API_KEY' n√£o encontrada no Cofre. Verifique o nome e se o acesso ao notebook est√° ligado.\")\n",
        "\n",
        "    if not os.environ[\"GOOGLE_API_KEY\"]:\n",
        "        print(\"ATEN√á√ÉO: Chave 'GOOGLE_API_KEY' n√£o encontrada no Cofre. Verifique o nome e se o acesso ao notebook est√° ligado.\")\n",
        "\n",
        "    print(\"Chaves de API carregadas do Cofre com sucesso.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao acessar o Cofre de Senhas: {e}\")\n",
        "    print(\"Por favor, verifique se voc√™ adicionou as chaves 'OPENAI_API_KEY' e 'GOOGLE_API_KEY' no menu üîë 'Secrets' √† esquerda.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOi0w9FT5O0V"
      },
      "outputs": [],
      "source": [
        "\n",
        "# C√âLULA 3: Cria√ß√£o do Arquivo do Agente (Backend)\n",
        "# O comando %%writefile DEVE ser a primeira linha desta c√©lula\n",
        "%%writefile agente_csv.py\n",
        "import os\n",
        "import zipfile\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Importando os LLMs de AMBOS os provedores\n",
        "from langchain_community.llms import OpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "\n",
        "# Lendo as duas chaves do ambiente (que a C√©lula 2 configurou)\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "def get_prompt_especializado(ramo_atividade: str) -> str:\n",
        "    \"\"\"\n",
        "    Cria o prompt com regras de neg√≥cio espec√≠ficas.\n",
        "    \"\"\"\n",
        "    prompt_especialista = f\"O ramo de atividade da empresa √©: **{ramo_atividade}**.\\n\"\n",
        "\n",
        "    if ramo_atividade == \"Ind√∫stria\":\n",
        "        prompt_especialista += \"REGRAS DE IND√öSTRIA: Preste aten√ß√£o em 'IPI' e 'Substitui√ß√£o Tribut√°ria'.\\n\"\n",
        "    elif ramo_atividade == \"Agroneg√≥cio\":\n",
        "        prompt_especialista += \"REGRAS DE AGRONEG√ìCIO: Monitore CFOPs espec√≠ficos do setor (Venda de produ√ß√£o, Insumos).\\n\"\n",
        "    elif ramo_atividade == \"Setor Automotivo\":\n",
        "        prompt_especialista += \"REGRAS DO SETOR AUTOMOTIVO: Valide notas fiscais de pe√ßas e servi√ßos, confira c√≥digos.\\n\"\n",
        "    elif ramo_atividade in [\"√ìrg√£os P√∫blicos\", \"Terceiro Setor\"]:\n",
        "         prompt_especialista += f\"REGRAS DE {ramo_atividade.upper()}: A an√°lise de 'Centros de Custo' √© priorit√°ria.\\n\"\n",
        "    else:\n",
        "        prompt_especialista += \"Nenhuma regra espec√≠fica de ramo. Siga as instru√ß√µes gerais.\\n\"\n",
        "\n",
        "    return prompt_especialista\n",
        "\n",
        "\n",
        "def responder(arquivo_zip_path: str, pergunta_usuario: str, ramo_atividade: str) -> str:\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal do agente, agora com l√≥gica de Fallback:\n",
        "    1. Tenta OpenAI\n",
        "    2. Se falhar, tenta Gemini\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Prepara√ß√£o (Leitura do CSV) ---\n",
        "    try:\n",
        "        temp_dir = tempfile.mkdtemp()\n",
        "        with zipfile.ZipFile(arquivo_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(temp_dir)\n",
        "\n",
        "        csv_files = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.endswith('.csv')]\n",
        "        if not csv_files:\n",
        "            return \"Nenhum arquivo CSV encontrado no ZIP.\"\n",
        "\n",
        "        caminho_csv = csv_files[0]\n",
        "\n",
        "        # --- L√ìGICA DE LEITURA ROBUSTA (MODIFICADO) ---\n",
        "        try:\n",
        "            # 1. Tenta o padr√£o (v√≠rgula, engine C, utf-8)\n",
        "            df = pd.read_csv(caminho_csv, encoding='utf-8')\n",
        "        except (pd.errors.ParserError, UnicodeDecodeError) as e:\n",
        "            print(f\"Falha na leitura padr√£o (v√≠rgula): {e}. Tentando com ponto-e-v√≠rgula...\")\n",
        "            try:\n",
        "                # 2. Tenta com ponto-e-v√≠rgula (comum no Brasil, latin1)\n",
        "                df = pd.read_csv(caminho_csv, sep=';', encoding='latin1')\n",
        "            except pd.errors.ParserError as e2:\n",
        "                print(f\"Falha com ponto-e-v√≠rgula: {e2}. Tentando pular linhas ruins...\")\n",
        "                try:\n",
        "                    # 3. Tenta pular linhas ruins (engine python)\n",
        "                    # on_bad_lines='skip' √© a chave aqui\n",
        "                    df = pd.read_csv(caminho_csv, encoding='latin1', engine='python', on_bad_lines='skip')\n",
        "                    print(f\"Aviso: O CSV foi lido pulando linhas mal formatadas.\")\n",
        "                except Exception as e_final:\n",
        "                    # 4. Falha total\n",
        "                    print(f\"Erro final de leitura: {e_final}\")\n",
        "                    return f\"Erro Cr√≠tico ao ler o CSV: O arquivo parece estar corrompido ou em formato desconhecido. Detalhe: {str(e_final)}\"\n",
        "        # --- FIM DA L√ìGICA DE LEITURA ROBUSTA ---\n",
        "\n",
        "    except Exception as e:\n",
        "        # Pega erros do ZIP ou outros erros de arquivo\n",
        "        return f\"Erro ao extrair o ZIP ou encontrar o CSV: {str(e)}\"\n",
        "\n",
        "    # --- 2. Constru√ß√£o do C√©rebro (Prompt) ---\n",
        "    prefixo_base = \"Voc√™ √© um assistente de dados avan√ßado que fala apenas portugu√™s. Voc√™ √© especialista em analisar DataFrames do Pandas.\"\n",
        "    prompt_especialista = get_prompt_especializado(ramo_atividade)\n",
        "    prefixo_final = prefixo_base + \"\\n\" + prompt_especialista\n",
        "\n",
        "    pergunta_para_agente = (\n",
        "        \"Tarefas:\\n\"\n",
        "        \"1. (TAREFA PRINCIPAL): Se as colunas 'Tipo_Documento' e 'Centro_Custo' n√£o existirem, crie-as e classifique CADA LINHA por tipo (compra, venda, servi√ßo) e por centros de custos.\\n\"\n",
        "        \"2. (TAREFA DO USU√ÅRIO): Ap√≥s a classifica√ß√£o, responda a esta pergunta: \"\n",
        "        f\"'{pergunta_usuario}'\\n\"\n",
        "        \"Responda ao usu√°rio em portugu√™s.\"\n",
        "    )\n",
        "\n",
        "    # --- 3. L√≥gica de Execu√ß√£o (OpenAI com Fallback para Gemini) ---\n",
        "\n",
        "    # TENTATIVA 1: OpenAI (O \"Engenheiro\" preferido)\n",
        "    try:\n",
        "        if not openai_api_key:\n",
        "            raise ValueError(\"OPENAI_API_KEY n√£o foi carregada do Cofre de Senhas.\")\n",
        "\n",
        "        print(\"Iniciando Tentativa 1 (OpenAI)...\")\n",
        "        llm_openai = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "\n",
        "        agente_openai = create_pandas_dataframe_agent(\n",
        "            llm_openai, df, prefix=prefixo_final, verbose=True,\n",
        "            allow_dangerous_code=True, agent_executor_kwargs={\"handle_parsing_errors\": True}\n",
        "        )\n",
        "\n",
        "        resposta = agente_openai.run(pergunta_para_agente)\n",
        "        print(\"Resposta obtida com OpenAI.\")\n",
        "        return f\"**(Respondido por: OpenAI)**\\n\\n\" + str(resposta)\n",
        "\n",
        "    except Exception as e_openai:\n",
        "        print(f\"Erro com OpenAI: {str(e_openai)}\")\n",
        "        print(\"Iniciando Tentativa 2 (Fallback com Gemini)...\")\n",
        "\n",
        "        # TENTATIVA 2: Gemini (O \"Estrategista\" de backup)\n",
        "        try:\n",
        "            if not google_api_key:\n",
        "                raise ValueError(\"GOOGLE_API_KEY n√£o foi carregada do Cofre de Senhas para o fallback.\")\n",
        "\n",
        "            llm_gemini = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-1.5-pro-latest\", # Recomendo 1.5 Pro\n",
        "                temperature=0,\n",
        "                google_api_key=google_api_key\n",
        "            )\n",
        "\n",
        "            agente_gemini = create_pandas_dataframe_agent(\n",
        "                llm_gemini, df, prefix=prefixo_final, verbose=True,\n",
        "                allow_dangerous_code=True, agent_executor_kwargs={\"handle_parsing_errors\": True}\n",
        "            )\n",
        "\n",
        "            resposta = agente_gemini.run(pergunta_para_agente)\n",
        "            print(\"Resposta obtida com Gemini (Fallback).\")\n",
        "            return f\"**(Respondido por: Gemini 1.5 Pro - Fallback)**\\n\\n\" + str(resposta)\n",
        "\n",
        "        except Exception as e_gemini:\n",
        "            print(f\"Erro com Gemini (Fallback): {str(e_gemini)}\")\n",
        "            return (\n",
        "                f\"**Erro Cr√≠tico: Ambos os agentes falharam.**\\n\\n\"\n",
        "                f\"**Erro OpenAI:** {str(e_openai)}\\n\\n\"\n",
        "                f\"**Erro Gemini (Fallback):** {str(e_gemini)}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SbQLIGpi5b3H"
      },
      "outputs": [],
      "source": [
        "# C√âLULA 4: Importa√ß√£o e Lan√ßamento do Frontend (Gradio)\n",
        "import gradio as gr\n",
        "import agente_csv\n",
        "\n",
        "print(\"\\nDepend√™ncias instaladas e agente_csv.py (com Fallback) criado.\")\n",
        "print(\"Iniciando a interface Gradio...\")\n",
        "\n",
        "# Fun√ß√£o ponte (sem mudan√ßas)\n",
        "def executar_agente_interface(arquivo_zip, ramo_atividade, pergunta_usuario):\n",
        "    if arquivo_zip is None:\n",
        "        return \"Erro: Por favor, fa√ßa o upload de um arquivo .ZIP.\"\n",
        "    if not pergunta_usuario:\n",
        "        return \"Erro: Por favor, digite uma pergunta.\"\n",
        "\n",
        "    caminho_zip = arquivo_zip.name\n",
        "    resposta_do_agente = agente_csv.responder(caminho_zip, pergunta_usuario, ramo_atividade)\n",
        "    return resposta_do_agente\n",
        "\n",
        "# Ramos de atividade (sem mudan√ßas)\n",
        "ramos_de_atividade = [\n",
        "    \"Ind√∫stria\", \"Agroneg√≥cio\", \"Setor Automotivo\", \"Servi√ßos\",\n",
        "    \"√ìrg√£os P√∫blicos\", \"Terceiro Setor\", \"Varejo\", \"Outro\"\n",
        "]\n",
        "\n",
        "# Constru√ß√£o da UI (sem mudan√ßas)\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ü§ñ Agente Aut√¥nomo para An√°lise de Documentos Fiscais\")\n",
        "    gr.Markdown(\"Fa√ßa o upload do seu arquivo **.ZIP**, selecione o ramo e fa√ßa sua pergunta.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            in_arquivo = gr.File(label=\"Upload do Arquivo .ZIP\", file_types=[\".zip\"])\n",
        "            in_ramo = gr.Dropdown(label=\"Selecione o Ramo de Atividade (Contexto)\", choices=ramos_de_atividade, value=\"Ind√∫stria\")\n",
        "            in_pergunta = gr.Textbox(label=\"Digite sua pergunta sobre os dados\", placeholder=\"Ex: Qual o valor total das notas fiscais de compra?\")\n",
        "            btn_processar = gr.Button(\"Perguntar ao Agente\", variant=\"primary\")\n",
        "        with gr.Column(scale=2):\n",
        "            out_resposta = gr.Markdown(label=\"Resposta do Agente\")\n",
        "\n",
        "    btn_processar.click(\n",
        "        fn=executar_agente_interface,\n",
        "        inputs=[in_arquivo, in_ramo, in_pergunta],\n",
        "        outputs=[out_resposta]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"### O agente tentar√° responder com OpenAI (GPT-4) e usar√° o Gemini 1.5 Pro como fallback.\")\n",
        "\n",
        "# 5. Lan√ßar a interface\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0QjcFAZVRKnWMIRvX+ys1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}